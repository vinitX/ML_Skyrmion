{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 1728) (1800, 1728) (1728,) (1728,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import data\n",
    "\n",
    "X_train = np.random.rand(7200,1728)\n",
    "X_test = np.random.rand(1800,1728)\n",
    "y_train = np.mean(X_train,axis=0)\n",
    "y_test = np.mean(X_test,axis=0)\n",
    "\n",
    "print(np.shape(X_train),np.shape(X_test),np.shape(y_train),np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train,(-1,1))\n",
    "y_test=np.reshape(y_test,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler.fit(y_train)\\ny_train = scaler.transform(y_train)\\ny_test = scaler.transform(y_test)\\n# Build X and y\\nX_train = data_train[:, 1:]\\ny_train = data_train[:, 0]\\nX_test = data_test[:, 1:]\\ny_test = data_test[:, 0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "'''\n",
    "scaler.fit(y_train)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Skinny\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model architecture parameters\n",
    "n_input = 1728\n",
    "n_neurons_1 = 2048\n",
    "n_neurons_2 = 1024\n",
    "n_neurons_3 = 512\n",
    "n_neurons_4 = 256\n",
    "n_target = 1\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_input])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Layer 1: Variables for hidden weights and biases\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_input, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "# Layer 2: Variables for hidden weights and biases\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "# Layer 3: Variables for hidden weights and biases\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "# Layer 4: Variables for hidden weights and biases\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output layer: Variables for output weights and biases\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))  #notice the change\n",
    "bias_out = tf.Variable(bias_initializer([n_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "hidden_1 = tf.nn.leaky_relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.leaky_relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.leaky_relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.leaky_relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (must be transposed)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out)) #notice the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "#mse = tf.losses.log_loss(np.abs(Y)+0.001, np.abs(out)+0.001)\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        [[23.062513 22.798088 22.420292 ... 22.627428 22.308397 22.701813]]\n",
      "                        [[-0.30637592 -0.2823919  -0.3910341  ... -0.24872117 -0.31222188\n",
      "  -0.3468105 ]]\n",
      "0.6714537 0.6668617\n",
      "                        [[3.0993645 3.0624356 3.0132844 ... 3.1530666 3.0653243 2.9275928]]\n",
      "                        [[-0.4914814  -0.6083073  -0.4791325  ... -0.60264975 -0.5176001\n",
      "  -0.594613  ]]\n",
      "1.122068 1.117864\n",
      "                        [[1.9195507 1.7625601 1.8777034 ... 1.8284391 1.8865442 1.8018926]]\n",
      "                        [[-0.14799127 -0.21863243 -0.12596866 ... -0.193755   -0.12720105\n",
      "  -0.18538865]]\n",
      "0.45661467 0.45810044\n",
      "                        [[1.5800327 1.4481585 1.5432491 ... 1.5148073 1.5578972 1.4839578]]\n",
      "                        [[0.39920276 0.3117935  0.3949527  ... 0.34726077 0.41339058 0.35105044]]\n",
      "0.019134114 0.01971825\n",
      "                        [[1.2873744 1.1722871 1.2634706 ... 1.2126741 1.2824713 1.2117794]]\n",
      "                        [[1.2957547 1.1782914 1.2616962 ... 1.2188061 1.281118  1.2235464]]\n",
      "0.5459265 0.54263955\n",
      "                        [[0.3116283  0.22578068 0.30178258 ... 0.2610595  0.315119   0.27024624]]\n",
      "                        [[1.0005744  0.90364087 0.9680153  ... 0.943028   0.9743527  0.9308789 ]]\n",
      "0.19565374 0.19470532\n",
      "                        [[ 0.00141662 -0.06125361 -0.001988   ... -0.02820784  0.00204342\n",
      "  -0.03500182]]\n",
      "                        [[0.5650792  0.4907998  0.5538534  ... 0.51830804 0.5576606  0.5199746 ]]\n",
      "0.0010653092 0.0010368896\n",
      "                        [[0.2086653  0.14272134 0.20493023 ... 0.16814749 0.20720379 0.17168395]]\n",
      "                        [[0.38180974 0.3189986  0.37440577 ... 0.33705142 0.38429406 0.34696773]]\n",
      "0.024951134 0.025210142\n",
      "                        [[0.43900365 0.37511772 0.427998   ... 0.39312762 0.44073516 0.40314347]]\n",
      "                        [[0.35071367 0.29001778 0.34043938 ... 0.30487293 0.3571301  0.31998855]]\n",
      "0.035356198 0.035608467\n",
      "                        [[0.583732   0.516117   0.56850755 ... 0.53393304 0.5856352  0.5478146 ]]\n",
      "                        [[0.39915052 0.33815542 0.38727215 ... 0.3525379  0.40355077 0.37001434]]\n",
      "0.0196015 0.019781912\n",
      "                        [[0.66144407 0.5936351  0.64562654 ... 0.6094655  0.66162753 0.62603045]]\n",
      "                        [[0.52343357 0.4599285  0.5086479  ... 0.473148   0.5249686  0.4920225 ]]\n",
      "0.0008133712 0.00084555865\n",
      "                        [[0.6375779  0.57116544 0.6208539  ... 0.58485377 0.63715756 0.6032982 ]]\n",
      "                        [[0.6355528  0.56972843 0.61782104 ... 0.58296794 0.6342209  0.60129946]]\n",
      "0.009512797 0.009439131\n",
      "                        [[0.48492104 0.4232108  0.47004038 ... 0.4352966  0.48598617 0.45441824]]\n",
      "                        [[0.5249558  0.4625948  0.50894517 ... 0.47416168 0.5249092  0.49338168]]\n",
      "0.0007579793 0.0007924734\n",
      "                        [[0.51335794 0.45136327 0.4974845  ... 0.46274322 0.5134265  0.48190838]]\n",
      "                        [[0.51483524 0.45305946 0.49860063 ... 0.46401265 0.5148835  0.48266187]]\n",
      "0.0011486555 0.0011956653\n",
      "                        [[0.5803527  0.51689166 0.562748   ... 0.5282683  0.5792307  0.54651314]]\n",
      "                        [[0.5620198  0.49932778 0.54460347 ... 0.51023376 0.56129515 0.52816916]]\n",
      "0.0010072194 0.0010129098\n",
      "                        [[0.5100799  0.4488247  0.4936841  ... 0.45930976 0.510117   0.47730654]]\n",
      "                        [[0.5252892  0.46388748 0.50808144 ... 0.4742526  0.5246743  0.49174932]]\n",
      "0.0007519352 0.0007944691\n",
      "                        [[0.5785939  0.51582474 0.56036144 ... 0.5265208  0.5771125  0.5438146 ]]\n",
      "                        [[0.4316483 0.3731944 0.4162758 ... 0.3824944 0.4328546 0.4005316]]\n",
      "0.011919397 0.0120511595\n",
      "                        [[0.66343594 0.5988792  0.6436981  ... 0.60978806 0.66107154 0.6273043 ]]\n",
      "                        [[0.2148117  0.16251184 0.20400967 ... 0.16996302 0.22050668 0.19103171]]\n",
      "0.1020634 0.10241708\n",
      "                        [[0.9535075  0.88126844 0.9279006  ... 0.8936259  0.9457808  0.91153854]]\n",
      "                        [[-0.03112355 -0.07658473 -0.03740135 ... -0.07264939 -0.02306858\n",
      "  -0.04810515]]\n",
      "0.31494796 0.3155534\n",
      "                        [[0.79982156 0.72962683 0.7782201  ... 0.74143726 0.7930687  0.7618204 ]]\n",
      "                        [[0.37570322 0.32189238 0.3650757  ... 0.32803416 0.37540114 0.34923816]]\n",
      "0.025600808 0.025765652\n"
     ]
    }
   ],
   "source": [
    "# Make Session\n",
    "net = tf.Session()\n",
    "# Run initializer\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "# Number of epochs and batch size\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "\n",
    "for e in range(epochs):\n",
    "    #print(e,end=' ')\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 5) == 0:\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: X_test})\n",
    "            \n",
    "    # Print final MSE after Training\n",
    "    mse_train = net.run(mse, feed_dict={X: X_train, Y: y_train})\n",
    "    mse_test = net.run(mse, feed_dict={X: X_test, Y: y_test})\n",
    "    print(mse_train, mse_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
